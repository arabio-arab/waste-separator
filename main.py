import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
import serial
import time

# D√©finir les cat√©gories de classification
categories = ["empty", "metal", "plastic"]

# Charger le mod√®le pr√©-entra√Æn√©

model = tf.keras.models.load_model(r"C:\Users\ARABI\Desktop\mobile net v2\separtor.h5")

# Configurer la connexion s√©rie avec Arduino
ser = serial.Serial('COM3', 9600)  # Remplacez 'COM3' par votre port
time.sleep(2)  # Attendre l'√©tablissement de la connexion s√©rie

def send_command_to_arduino(command):
    ser.write(f"{command}\n".encode())  # Envoyer la commande √† Arduino

def classify_frame(frame):
    # Redimensionner l'image pour MobileNetV2 (224x224 pixels)
    img = cv2.resize(frame, (224, 224))
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    # Pr√©dire la classe de l'image
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions)
    confidence = predictions[0][predicted_class]

    # Retourner la classe pr√©dite et la confiance
    return categories[predicted_class], confidence

# Interface utilisateur avec Streamlit
st.title("üö¶FST-BM Mechatronicüê±‚Äçüèç")
FRAME_WINDOW = st.image([])  # Espace r√©serv√© pour l'image
run = st.checkbox('Run')  # Bouton pour d√©marrer/arr√™ter la capture vid√©o

# Slider pour ajuster le seuil de confiance
confidence_threshold = st.slider("Seuil de confiance", min_value=0.0, max_value=1.0, value=0.5, step=0.05, key="confidence_threshold_slider")
label_output = "empty"
cap = cv2.VideoCapture(0)  # Initialiser la capture vid√©o (webcam)
progress_bar = st.progress(0)  # Bar de progression

while run:
    ret, frame = cap.read()  # Lire une image depuis la webcam
    if not ret:
        break
    
    # Conversion de l'image en RGB (par d√©faut OpenCV est en BGR)
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Classification de l'image captur√©e
    predicted_class, confidence = classify_frame(frame)

    # Si la confiance d√©passe le seuil, afficher et envoyer la commande
    if confidence >= confidence_threshold:
        label = f"Classe: {predicted_class}, Confiance: {confidence:.2f}%"
        cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)

        # Envoyer la commande correspondante √† l'Arduino
        if predicted_class == "empty":
            send_command_to_arduino("0")
        elif predicted_class == "metal":
            send_command_to_arduino("1")
        elif predicted_class == "plastic":
            send_command_to_arduino("2")

        # Mettre √† jour la barre de progression avec la confiance
        progress_bar.progress(int(confidence * 100))

    # Afficher le flux vid√©o dans Streamlit
    FRAME_WINDOW.image(frame, width=600)

# Lib√©rer la capture vid√©o et fermer la connexion s√©rie
cap.release()
ser.close()